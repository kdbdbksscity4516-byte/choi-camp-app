import streamlit as st
import pandas as pd
import urllib.parse
from datetime import datetime, timedelta, timezone
import requests
from geopy.distance import geodesic
import folium
from streamlit_folium import folium_static
import time

# 1. ì„¤ì • ì •ë³´
sheet_url = "https://docs.google.com/spreadsheets/d/1XsTB4nUPL03xba1cEGYGUsyNZcmsdFEGEU2S-6DfpL4/export?format=csv"
script_url = "https://script.google.com/macros/s/AKfycbzlPtAOqvz0wSgbspGz9PbZuDcdd-BBtbbep_uEtCFTaBd4vYG5Pu6jo0dkESkVBIgI/exec"

KST = timezone(timedelta(hours=9))
now_kst = datetime.now(KST)

st.set_page_config(page_title="ìµœì›…ì‹ í›„ë³´ìë‹˜ ë™ì„ ", layout="centered")

def update_sheet_status(row_idx, status_text):
    api_url = f"{script_url}?row={row_idx}&status={urllib.parse.quote(status_text)}"
    try:
        res = requests.get(api_url, timeout=15)
        if "ì„±ê³µ" in res.text:
            st.toast(f"âœ… {status_text} ì²˜ë¦¬ ì™„ë£Œ")
            return True
    except:
        st.error("ğŸ“¡ ì‹œíŠ¸ ì—°ê²° ì‹¤íŒ¨")
    return False

st.markdown("""<style> div.stButton > button { width: 100% !important; height: 50px !important; } </style>""", unsafe_allow_html=True)

try:
    # ë°ì´í„° ê°•ì œ ë¡œë“œ
    fresh_url = f"{sheet_url}&t={int(time.time())}"
    df = pd.read_csv(fresh_url)
    
    # [ì¤‘ìš”] ëª¨ë“  ê³µë€ì„ "ë¯¸ì²´í¬"ë¡œ ë¯¸ë¦¬ ì±„ì›Œì¤ë‹ˆë‹¤.
    df = df.fillna("")
    df.loc[df['ì°¸ì„ì—¬ë¶€'] == "", 'ì°¸ì„ì—¬ë¶€'] = "ë¯¸ì²´í¬"
    
    if df.empty:
        st.error("âš ï¸ ì‹œíŠ¸ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    df['ìœ„ë„'] = pd.to_numeric(df['ìœ„ë„'], errors='coerce')
    df['ê²½ë„'] = pd.to_numeric(df['ê²½ë„'], errors='coerce')
    df['ë‚ ì§œ_str'] = df['ë‚ ì§œ'].astype(str).str.strip()
    
    if 'ì‚¬ì§„' in df.columns:
        photo_list = [p for p in df['ì‚¬ì§„'].tolist() if str(p).startswith('http')]
        if photo_list:
            st.image(photo_list[0], use_container_width=True)

    st.title("ğŸš© ìµœì›…ì‹ í›„ë³´ìë‹˜ ë™ì„ ")

    available_dates = sorted([d for d in df['ë‚ ì§œ_str'].unique() if d and d != "nan"])
    today_str = now_kst.strftime('%Y-%m-%d')
    default_idx = 0
    for i, d in enumerate(available_dates):
        if today_str in d:
            default_idx = i
            break
            
    selected_date = st.selectbox("ğŸ—“ï¸ ë‚ ì§œ ì„ íƒ", available_dates, index=default_idx)
    
    if st.button("ğŸ”„ ìƒˆë¡œìš´ ì¼ì • ë¶ˆëŸ¬ì˜¤ê¸°"):
        st.cache_data.clear()
        st.rerun()
    st.divider()

    day_df = df[df['ë‚ ì§œ_str'] == selected_date].copy().reset_index()
    
    if not day_df.empty:
        day_df['temp_time_dt'] = pd.to_datetime(day_df['ì‹œê°„'], errors='coerce')
        day_df['ì°¸ì„ì‹œê°„_dt'] = pd.to_datetime(day_df['ì°¸ì„ì‹œê°„'], errors='coerce')
        
        times = sorted(day_df['temp_time_dt'].dropna().unique())
        final_list = []
        last_ref = None
        
        # ë§ˆì§€ë§‰ ì°¸ì„ì§€ ê¸°ì¤€
        last_att = day_df[day_df['ì°¸ì„ì—¬ë¶€'] == 'ì°¸ì„'].sort_values('ì°¸ì„ì‹œê°„_dt')
        if not last_att.empty:
            row = last_att.iloc[-1]
            if not pd.isna(row['ìœ„ë„']):
                last_ref = (row['ìœ„ë„'], row['ê²½ë„'])

        for t in times:
            group = day_df[day_df['temp_time_dt'] == t].copy()
            group_att = group[group['ì°¸ì„ì—¬ë¶€'] == 'ì°¸ì„'].sort_values('ì°¸ì„ì‹œê°„_dt')
            group_pending = group[group['ì°¸ì„ì—¬ë¶€'] == 'ë¯¸ì²´í¬'].copy()
            
            if not group_pending.empty:
                if last_ref:
                    group_pending['dist'] = group_pending.apply(lambda r: geodesic(last_ref, (r['ìœ„ë„'], r['ê²½ë„'])).meters if not pd.isna(r['ìœ„ë„']) else 999999, axis=1)
                else:
                    group_pending['dist'] = 0
                group_pending = group_pending.sort_values('dist')

            group_no = group[group['ì°¸ì„ì—¬ë¶€'] == 'ë¶ˆì°¸ì„']
            sorted_group = pd.concat([group_att, group_pending, group_no])
            final_list.append(sorted_group)
            
            if not sorted_group.empty:
                v = sorted_group[sorted_group['ì°¸ì„ì—¬ë¶€'] != 'ë¶ˆì°¸ì„']
                if not v.empty and not pd.isna(v.iloc[-1]['ìœ„ë„']):
                    last_ref = (v.iloc[-1]['ìœ„ë„'], v.iloc[-1]['ê²½ë„'])

        display_df = pd.concat(final_list)

        # ì§€ë„ í‘œì‹œ
        st.subheader("ğŸ“ ì‹¤ì‹œê°„ ë™ì„  ì§€ë„")
        m_df = display_df[display_df['ì°¸ì„ì—¬ë¶€'] != 'ë¶ˆì°¸ì„']
        m_df = m_df[m_df['ìœ„ë„'].notna() & m_df['ê²½ë„'].notna()]
        if not m_df.empty:
            m = folium.Map(location=[m_df.iloc[0]['ìœ„ë„'], m_df.iloc[0]['ê²½ë„']], zoom_start=11)
            pts = []
            for _, r in m_df.iterrows():
                color = 'blue' if r['ì°¸ì„ì—¬ë¶€'] == 'ì°¸ì„' else 'red'
                folium.Marker([r['ìœ„ë„'], r['ê²½ë„']], popup=r['í–‰ì‚¬ëª…'], icon=folium.Icon(color=color)).add_to(m)
                pts.append([r['ìœ„ë„'], r['ê²½ë„']])
            if len(pts) > 1:
                folium.PolyLine(pts, color="red", weight=3).add_to(m)
            folium_static(m)

        # ë¦¬ìŠ¤íŠ¸ í‘œì‹œ
        for _, row in display_df.iterrows():
            orig_idx = row['index']
            with st.container(border=True):
                st.markdown(f"### {row['ì‹œê°„']} | {row['í–‰ì‚¬ëª…']}")
                st.caption(f"ğŸ“ {row['ì£¼ì†Œ']}")
                status = str(row['ì°¸ì„ì—¬ë¶€']).strip()
                
                if status == "ë¯¸ì²´í¬":
                    c1, c2 = st.columns(2)
                    if c1.button("ğŸŸ¢ ì°¸ì„", key=f"at_{orig_idx}"):
                        if update_sheet_status(orig_idx, "ì°¸ì„"): st.rerun()
                    if c2.button("ğŸ”´ ë¶ˆì°¸ì„", key=f"no_{orig_idx}"):
                        if update_sheet_status(orig_idx, "ë¶ˆì°¸ì„"): st.rerun()
                else:
                    st.success(f"ê²°ê³¼: {status}")
                    if st.button("ğŸ”„ ì¬ì„ íƒ", key=f"re_{orig_idx}"):
                        if update_sheet_status(orig_idx, "ë¯¸ì²´í¬"): st.rerun()
                st.link_button("ğŸš• ì¹´ì¹´ì˜¤ë‚´ë¹„", f"https://map.kakao.com/link/search/{urllib.parse.quote(str(row['ì£¼ì†Œ']))}")
    else:
        st.info("ì„ íƒí•œ ë‚ ì§œì— ì¼ì •ì´ ì—†ìŠµë‹ˆë‹¤.")

except Exception as e:
    st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
